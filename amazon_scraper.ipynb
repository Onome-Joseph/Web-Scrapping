{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d523a338-5fc2-4e97-9b25-969ca93dd98f",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22a24d89-9ae4-44af-b0f2-b8adf6759d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b642b71-92c0-4656-acc8-440ba954614c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping complete. Data saved to amazon_products.csv.\n"
     ]
    }
   ],
   "source": [
    "# Base URL for Amazon's mobile accessories category\n",
    "BASE_URL = \"https://www.amazon.in/s?rh=n%3A6612025031&fs=true&ref=lp_6612025031_sar\"\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "USER_AGENTS = [\n",
    "    # Desktop User-Agents\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.6099.224 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.6045.123 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.5993.88 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:110.0) Gecko/20100101 Firefox/110.0\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7; rv:109.0) Gecko/20100101 Firefox/109.0\",\n",
    "    \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:108.0) Gecko/20100101 Firefox/108.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/119.0.2140.60 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Version/17.0 Safari/537.36\",\n",
    "\n",
    "    # Mobile User-Agents (Android & iPhone)\n",
    "    \"Mozilla/5.0 (Linux; Android 13; Pixel 7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.6099.224 Mobile Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 17_2 like Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Linux; Android 12; Samsung Galaxy S22) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.6045.123 Mobile Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 16_5 like Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Linux; U; Android 10; en-us; Redmi Note 9) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Mobile Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Linux; U; Android 11; en-us; OnePlus Nord) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.5993.88 Mobile Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Linux; Android 14; Pixel 8 Pro) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.6190.71 Mobile Safari/537.36\",\n",
    "]\n",
    "\n",
    "def get_random_headers():\n",
    "    return {\n",
    "        \"User-Agent\": random.choice(USER_AGENTS),\n",
    "        \"Accept-Language\": \"en-US, en;q=0.5\",\n",
    "    }\n",
    "\n",
    "def get_soup(url):\n",
    "    \"\"\"Fetches and parses the HTML content of a given URL.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=get_random_headers())\n",
    "        response.raise_for_status()\n",
    "        return BeautifulSoup(response.text, 'html.parser')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_product_info(item):\n",
    "    \"\"\"Extracts product details from a single item.\"\"\"\n",
    "    product_data = {}\n",
    "    try:\n",
    "        rating = item.find(\"span\", class_=\"a-icon-alt\").text.split()[0]\n",
    "    except AttributeError:\n",
    "        rating = \"N/A\"\n",
    "\n",
    "    try:\n",
    "        product_url = \"https://www.amazon.in\" + item.find(\"a\", class_=\"a-link-normal s-line-clamp-4 s-link-style a-text-normal\")[\"href\"]\n",
    "    except (AttributeError, TypeError):\n",
    "        return None  # Skip if no product URL\n",
    "\n",
    "    # Visit product page to get seller info and stock status\n",
    "    product_soup = get_soup(product_url)\n",
    "    if product_soup:\n",
    "        try:\n",
    "            stock_status = product_soup.find(\"span\", class_=\"a-size-medium a-color-success\").text.strip()\n",
    "            if \"Currently unavailable\" in stock_status or \"Out of stock\" in stock_status:\n",
    "                return None  # Skip out-of-stock items\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            seller = product_soup.find(\"a\", id=\"sellerProfileTriggerId\").text.strip()\n",
    "        except AttributeError:\n",
    "            seller = \"N/A\"\n",
    "        \n",
    "        try:\n",
    "            name = product_soup.find(\"span\", id=\"productTitle\").text.strip()\n",
    "        except AttributeError:\n",
    "            name = \"N/A\"\n",
    "\n",
    "        try:\n",
    "            price = product_soup.find(\"span\", class_=\"a-price-whole\").text.strip()\n",
    "        except AttributeError:\n",
    "            price = \"N/A\"\n",
    "\n",
    "        product_data = {\n",
    "            \"Product Name\": name,\n",
    "            \"Price (INR)\": price,\n",
    "            \"Rating\": rating,\n",
    "            \"Seller Name\": seller\n",
    "        }\n",
    "\n",
    "    return product_data\n",
    "\n",
    "def scrape_amazon():\n",
    "    \"\"\"Scrapes multiple pages of Amazon search results and saves data to a CSV file.\"\"\"\n",
    "    all_products = []\n",
    "    page = 1\n",
    "    max_pages = 5  # Adjust as needed\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        while page <= max_pages:\n",
    "            url = f\"{BASE_URL}&page={page}\"\n",
    "            print(f\"Scraping page {page}...\")\n",
    "            soup = get_soup(url)\n",
    "            if not soup:\n",
    "                break\n",
    "\n",
    "            products = []\n",
    "            items = soup.find_all(\"div\", class_=\"s-result-item\")\n",
    "            results = executor.map(extract_product_info, items)  # Parallel processing\n",
    "\n",
    "            # Collect non-None results\n",
    "            for product in results:\n",
    "                if product:\n",
    "                    products.append(product)\n",
    "\n",
    "            all_products.extend(products)\n",
    "            page += 1\n",
    "\n",
    "    # Save data to CSV\n",
    "    with open(\"amazon_products.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"Product Name\", \"Price (INR)\", \"Rating\", \"Seller Name\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_products)\n",
    "\n",
    "    print(\"Scraping complete. Data saved to amazon_products.csv.\")\n",
    "    return all_products\n",
    "\n",
    "# Execute the scraper\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_amazon()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589beea-c162-4036-a354-0ac439fa992a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
